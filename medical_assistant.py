#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒ»ç–—åŠ©æ‰‹é›†æˆè„šæœ¬
åŸºäº Qwen3-0.6B åŒ»ç–—å¾®è°ƒæ¨¡å‹ï¼Œæä¾›å¿ƒç†ç–¾ç—…åŒ»ç–—åœºæ™¯çš„æ™ºèƒ½åŠ©æ‰‹åŠŸèƒ½
"""

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import argparse
import json
import time
from datetime import datetime
import os

# åŒ»ç–—ä¸“ä¸šæç¤ºè¯æ¨¡æ¿
MENTAL_HEALTH_PROMPTS = {
    "assessment": "You are a licensed psychologist. Carefully assess the user's described emotions, thoughts, and behaviors, and provide a professional preliminary evaluation of their mental state.",
    "therapy": "You are a certified psychotherapist. Based on the user's emotional and psychological issues, suggest appropriate therapeutic approaches such as CBT, mindfulness, or counseling strategies.",
    "coping_strategies": "You are a mental health counselor. Provide practical coping techniques and emotional regulation methods to help the user manage stress, anxiety, or depression.",
    "self_care": "You are a wellness coach specializing in mental health. Give evidence-based self-care recommendations, including lifestyle habits that promote psychological well-being.",
    "crisis_intervention": "You are a crisis counselor. Evaluate whether the described situation may require immediate professional or emergency help, and provide calm, safety-focused guidance.",
    "education": "You are a psychology educator. Explain mental health concepts in a simple and empathetic way, helping the user understand their emotions and possible psychological conditions.",
    "motivation": "You are a positive psychology expert. Provide supportive and encouraging messages that help the user build resilience and maintain motivation through difficult times.",
    "mindfulness": "You are a mindfulness coach. Guide the user through relaxation and mindfulness practices to reduce anxiety and increase present-moment awareness.",
    "relationship_support": "You are a relationship therapist. Offer professional advice on communication, emotional boundaries, and healthy relationship dynamics.",
    "work_stress": "You are an occupational psychologist. Help the user address workplace stress, burnout, and work-life balance challenges with practical psychological tools."
}


# å¸¸è§åŒ»ç–—åœºæ™¯
MENTAL_HEALTH_SCENARIOS = {
    "1": "Emotional Assessment",            # æƒ…ç»ªè¯„ä¼°
    "2": "Therapy and Counseling",          # å¿ƒç†æ²»ç–—ä¸å’¨è¯¢
    "3": "Stress Management",               # å‹åŠ›ç®¡ç†
    "4": "Psychoeducation",                 # å¿ƒç†å¥åº·æ•™è‚²
    "5": "Crisis Intervention",             # å¿ƒç†å±æœºå¹²é¢„
    "6": "Mindfulness and Relaxation",      # æ­£å¿µä¸æ”¾æ¾è®­ç»ƒ
    "7": "Coping Strategies",               # åº”å¯¹ç­–ç•¥ä¸æƒ…ç»ªè°ƒèŠ‚
    "8": "Relationship and Communication",  # äººé™…å…³ç³»ä¸æ²Ÿé€š
    "9": "Work-Life Balance",               # å·¥ä½œä¸ç”Ÿæ´»å¹³è¡¡
    "10": "Self-esteem and Motivation"      # è‡ªå°Šä¸è‡ªæˆ‘æ¿€åŠ±
}


MENTAL_HEALTH_SAMPLE_QUESTIONS = {
    "assessment": [
        "I've been feeling anxious for weeks. Could this be a sign of an anxiety disorder?",
        "I often feel sad and unmotivated. How do I know if I might be depressed?",
        "Lately, Iâ€™ve been having trouble sleeping and concentrating â€” could this be related to stress?"
    ],
    "therapy": [
        "What kinds of therapy are effective for treating anxiety or depression?",
        "How can I find a good therapist that suits my needs?",
        "Whatâ€™s the difference between cognitive behavioral therapy (CBT) and talk therapy?"
    ],
    "coping_strategies": [
        "How can I calm myself down when I feel overwhelmed?",
        "What are some healthy ways to manage work-related stress?",
        "How do I deal with constant negative thoughts?"
    ],
    "self_care": [
        "What are some daily self-care habits that can improve my mental health?",
        "How can I build emotional resilience in my daily life?",
        "Whatâ€™s a good morning routine for better mental well-being?"
    ],
    "education": [
        "What exactly is anxiety and how does it affect the brain?",
        "How does depression differ from just feeling sad?",
        "What are common misconceptions about mental illness?"
    ],
    "crisis_intervention": [
        "What should I do if I have thoughts of self-harm?",
        "How can I support a friend who might be in a mental health crisis?",
        "When should I seek emergency help for mental distress?"
    ],
    "relationship_support": [
        "How can I handle conflicts with my partner in a healthy way?",
        "What are the signs of a toxic relationship?",
        "How can I communicate my feelings more effectively?"
    ],
    "work_stress": [
        "How can I manage burnout from long working hours?",
        "What are effective ways to balance work and personal life?",
        "How can I deal with pressure from a demanding boss?"
    ],
    "mindfulness": [
        "How do I start practicing mindfulness or meditation?",
        "What are simple breathing exercises to reduce anxiety?",
        "How can mindfulness help me manage emotions?"
    ],
    "motivation": [
        "I feel stuck and unmotivated â€” how can I regain focus?",
        "How do I stay positive during tough times?",
        "What are practical ways to build self-confidence?"
    ]
}


class MedicalAssistant:
    def __init__(self, checkpoint_path="./output/Qwen3-0.6B/checkpoint-1580"):
        """åˆå§‹åŒ–åŒ»ç–—åŠ©æ‰‹"""
        self.checkpoint_path = checkpoint_path
        self.device, self.dtype = self._select_device_and_dtype()
        self.model = None
        self.tokenizer = None
        self.conversation_history = []
        
    def _select_device_and_dtype(self):
        """é€‰æ‹©è®¾å¤‡å’Œæ•°æ®ç±»å‹"""
        if torch.cuda.is_available():
            try:
                major, _ = torch.cuda.get_device_capability()
                if major >= 12:
                    raise RuntimeError("Unsupported CUDA capability for current PyTorch")
                _ = torch.zeros(1, device="cuda")
                return "cuda", torch.float16
            except Exception:
                pass
        return "cpu", torch.float32
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨"""
        print("æ­£åœ¨åŠ è½½åŒ»ç–—åŠ©æ‰‹æ¨¡å‹...")
        
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.checkpoint_path):
            raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.checkpoint_path}")
        
        # åŠ è½½åˆ†è¯å™¨
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.checkpoint_path, 
            use_fast=False, 
            trust_remote_code=True,
            local_files_only=True  # åªä½¿ç”¨æœ¬åœ°æ–‡ä»¶
        )
        if self.tokenizer.pad_token is None and self.tokenizer.eos_token is not None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        # åŠ è½½æ¨¡å‹
        self.model = AutoModelForCausalLM.from_pretrained(
            self.checkpoint_path, 
            torch_dtype=self.dtype,
            local_files_only=True  # åªä½¿ç”¨æœ¬åœ°æ–‡ä»¶
        )
        self.model.to(self.device)
        self.model.eval()
        
        print(f"æ¨¡å‹åŠ è½½å®Œæˆï¼ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def predict(self, messages, max_new_tokens=512):
        """æ‰§è¡Œé¢„æµ‹"""
        model_device = next(self.model.parameters()).device
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True,
        )
        inputs = self.tokenizer([text], return_tensors="pt")
        input_ids = inputs.input_ids.to(model_device)
        attention_mask = inputs.attention_mask.to(model_device) if hasattr(inputs, "attention_mask") else None

        generated = self.model.generate(
            input_ids=input_ids,
            attention_mask=attention_mask,
            max_new_tokens=max_new_tokens,
        )

        # åªè§£ç æ–°ç”Ÿæˆéƒ¨åˆ†
        new_tokens = generated[:, input_ids.shape[1]:]
        response = self.tokenizer.batch_decode(new_tokens, skip_special_tokens=True)[0]
        return response
    
    def ask_question(self, question, scenario_type="diagnosis", max_tokens=512):
        """è¯¢é—®åŒ»ç–—é—®é¢˜"""
        if scenario_type not in MENTAL_HEALTH_PROMPTS:
            scenario_type = "diagnosis"
        
        messages = [
            {"role": "system", "content": MENTAL_HEALTH_PROMPTS[scenario_type]},
            {"role": "user", "content": question}
        ]
        
        # è®°å½•å¯¹è¯å†å²
        self.conversation_history.append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "scenario": scenario_type,
            "question": question,
            "response": None
        })
        
        response = self.predict(messages, max_new_tokens=max_tokens)
        
        # æ›´æ–°å¯¹è¯å†å²
        self.conversation_history[-1]["response"] = response
        
        return response
    
    def show_scenarios(self):
        """æ˜¾ç¤ºå¯ç”¨çš„åŒ»ç–—åœºæ™¯"""
        print("\nğŸ¥ åŒ»ç–—åŠ©æ‰‹ - å¯ç”¨åœºæ™¯:")
        print("=" * 50)
        for key, value in MENTAL_HEALTH_SCENARIOS.items():
            print(f"{key:2}. {value}")
        print("=" * 50)
    
    def show_sample_questions(self, scenario_type):
        """æ˜¾ç¤ºç¤ºä¾‹é—®é¢˜"""
        if scenario_type in MENTAL_HEALTH_SAMPLE_QUESTIONS:
            print(f"\nğŸ“‹ {MENTAL_HEALTH_SCENARIOS.get(scenario_type, 'åŒ»ç–—å’¨è¯¢')} - ç¤ºä¾‹é—®é¢˜:")
            print("-" * 40)
            for i, question in enumerate(MENTAL_HEALTH_SAMPLE_QUESTIONS[scenario_type], 1):
                print(f"{i}. {question}")
            print("-" * 40)
    
    def interactive_mode(self):
        """äº¤äº’æ¨¡å¼"""
        print("\nğŸ¤– åŒ»ç–—åŠ©æ‰‹å·²å¯åŠ¨ï¼")
        print("è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©ï¼Œè¾“å…¥ 'quit' é€€å‡º")
        
        while True:
            try:
                # æ˜¾ç¤ºåœºæ™¯é€‰æ‹©
                self.show_scenarios()
                
                # é€‰æ‹©åœºæ™¯
                scenario_choice = input("\nè¯·é€‰æ‹©åŒ»ç–—åœºæ™¯ (1-10): ").strip()
                if scenario_choice == 'quit':
                    break
                elif scenario_choice == 'help':
                    self.show_help()
                    continue
                elif scenario_choice not in MENTAL_HEALTH_SCENARIOS:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
                
                # è·å–åœºæ™¯ç±»å‹
                scenario_type = list(MENTAL_HEALTH_PROMPTS.keys())[int(scenario_choice) - 1]
                
                # æ˜¾ç¤ºç¤ºä¾‹é—®é¢˜
                self.show_sample_questions(scenario_type)
                
                # è·å–ç”¨æˆ·é—®é¢˜
                question = input(f"\nè¯·è¾“å…¥æ‚¨çš„{MENTAL_HEALTH_SCENARIOS[scenario_choice]}é—®é¢˜: ").strip()
                if not question:
                    print("âŒ é—®é¢˜ä¸èƒ½ä¸ºç©º")
                    continue
                
                # ç”Ÿæˆå›ç­”
                print("\nğŸ”„ æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜...")
                start_time = time.time()
                
                response = self.ask_question(question, scenario_type)
                
                end_time = time.time()
                
                # æ˜¾ç¤ºå›ç­”
                elapsed_time = end_time - start_time
                print(f"\nğŸ’¡ åŒ»ç–—åŠ©æ‰‹å›ç­” (è€—æ—¶: {elapsed_time:.2f}ç§’):")
                print("=" * 60)
                print(response)
                print("=" * 60)
                
                # è¯¢é—®æ˜¯å¦ç»§ç»­
                continue_choice = input("\næ˜¯å¦ç»§ç»­å’¨è¯¢ï¼Ÿ(y/n): ").strip().lower()
                if continue_choice in ['n', 'no', 'å¦']:
                    break
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨åŒ»ç–—åŠ©æ‰‹ï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
                continue
    
    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print("\nğŸ“– åŒ»ç–—åŠ©æ‰‹ä½¿ç”¨å¸®åŠ©:")
        print("=" * 50)
        print("1. é€‰æ‹©åŒ»ç–—åœºæ™¯ (1-10)")
        print("2. è¾“å…¥æ‚¨çš„åŒ»ç–—é—®é¢˜")
        print("3. è·å¾—ä¸“ä¸šçš„åŒ»ç–—å»ºè®®")
        print("\nğŸ’¡ æç¤º:")
        print("- æœ¬åŠ©æ‰‹ä»…æä¾›å‚è€ƒå»ºè®®ï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—è¯Šæ–­")
        print("- ç´§æ€¥æƒ…å†µè¯·ç«‹å³å°±åŒ»")
        print("- è¾“å…¥ 'quit' é€€å‡ºç¨‹åº")
        print("=" * 50)
    
    def save_conversation(self, filename=None):
        """ä¿å­˜å¯¹è¯å†å²"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"medical_conversation_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ å¯¹è¯å†å²å·²ä¿å­˜åˆ°: {filename}")
    
    def batch_questions(self, questions_file):
        """æ‰¹é‡å¤„ç†é—®é¢˜"""
        try:
            with open(questions_file, 'r', encoding='utf-8') as f:
                questions = json.load(f)
            
            print(f"ğŸ“ å¼€å§‹æ‰¹é‡å¤„ç† {len(questions)} ä¸ªé—®é¢˜...")
            
            results = []
            for i, q in enumerate(questions, 1):
                print(f"\nå¤„ç†ç¬¬ {i}/{len(questions)} ä¸ªé—®é¢˜...")
                response = self.ask_question(
                    q.get('question', ''), 
                    q.get('scenario', 'diagnosis'),
                    q.get('max_tokens', 512)
                )
                
                results.append({
                    "question": q.get('question', ''),
                    "scenario": q.get('scenario', 'diagnosis'),
                    "response": response
                })
            
            # ä¿å­˜ç»“æœ
            output_file = f"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")


def main():
    parser = argparse.ArgumentParser(description="åŒ»ç–—åŠ©æ‰‹ - åŸºäºQwen3-0.6Bçš„æ™ºèƒ½åŒ»ç–—å’¨è¯¢ç³»ç»Ÿ")
    parser.add_argument("--checkpoint", "-c", type=str, 
                       default="./output/Qwen3-0.6B/checkpoint-1580",
                       help="æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„")
    parser.add_argument("--question", "-q", type=str, 
                       help="ç›´æ¥è¯¢é—®é—®é¢˜ï¼ˆéœ€è¦é…åˆ --scenario ä½¿ç”¨ï¼‰")
    parser.add_argument("--scenario", "-s", type=str, 
                       default="diagnosis", 
                       choices=list(MENTAL_HEALTH_PROMPTS.keys()),
                       help="åŒ»ç–—åœºæ™¯ç±»å‹")
    parser.add_argument("--max-tokens", "-m", type=int, 
                       default=512, 
                       help="æœ€å¤§ç”Ÿæˆtokenæ•°")
    parser.add_argument("--batch", "-b", type=str, 
                       help="æ‰¹é‡å¤„ç†é—®é¢˜æ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰")
    parser.add_argument("--save-history", action="store_true", 
                       help="ä¿å­˜å¯¹è¯å†å²")
    
    args = parser.parse_args()
    
    # åˆ›å»ºåŒ»ç–—åŠ©æ‰‹å®ä¾‹
    assistant = MedicalAssistant(args.checkpoint)
    
    # åŠ è½½æ¨¡å‹
    assistant.load_model()
    
    if args.batch:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        assistant.batch_questions(args.batch)
    elif args.question:
        # å•æ¬¡é—®ç­”æ¨¡å¼
        print(f"ğŸ¤– åŒ»ç–—åŠ©æ‰‹å›ç­”:")
        print("=" * 50)
        response = assistant.ask_question(args.question, args.scenario, args.max_tokens)
        print(response)
        print("=" * 50)
    else:
        # äº¤äº’æ¨¡å¼
        assistant.interactive_mode()
    
    # ä¿å­˜å¯¹è¯å†å²
    if args.save_history and assistant.conversation_history:
        assistant.save_conversation()


if __name__ == "__main__":
    main()
